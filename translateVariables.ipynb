{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get all variables ###\n",
    "import os, json\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Show the numbers of PDFs in each category ###\n",
    "# count_original_pdf = 0\n",
    "# original_folders = [x[0] for x in os.walk(os.getcwd() + \"/MicrodataFiles/\")]\n",
    "\n",
    "# for each in range(1, len(original_folders)):\n",
    "#     extracted_pdfs = [f for f in listdir(original_folders[each]) if isfile(join(original_folders[each], f))]\n",
    "#     count_original_pdf = count_original_pdf + len(extracted_pdfs)\n",
    "#     print(original_folders[each])\n",
    "#     print(len(extracted_pdfs))\n",
    "# print(count_original_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Show the numbers of variables in each category ###\n",
    "# count_original_variable = 0\n",
    "# original_folders = [x[0] for x in os.walk(os.getcwd() + \"/ExtractFiles/\")]\n",
    "\n",
    "# for each in range(1, len(original_folders)):\n",
    "#     extracted_pdfs = [f for f in listdir(original_folders[each]) if isfile(join(original_folders[each], f))]\n",
    "    \n",
    "#     for item in extracted_pdfs:\n",
    "#         try:\n",
    "#             with open(original_folders[each] + '/' + item, 'rb') as f:\n",
    "#                 read_title = json.load(f)\n",
    "#         except:\n",
    "#             print(item)\n",
    "        \n",
    "#         count_original_variable = count_original_variable + len(read_title.keys()) - 1\n",
    "# print(count_original_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Show the numbers of JSONs (extracted info files) in each category ###\n",
    "def read_title_info (Topics_File_Folder, Variables_File_Folder):\n",
    "    \n",
    "    variables_table = []\n",
    "    topics_table = []\n",
    "    extracted_title_folders = [x[0] for x in os.walk(os.getcwd() + Topics_File_Folder)] \n",
    "    count_failed_info_file = 0\n",
    "\n",
    "\n",
    "    for each in range(1, len(extracted_title_folders)):\n",
    "\n",
    "        extracted_title_json = [f for f in listdir(extracted_title_folders[each]) if isfile(join(extracted_title_folders[each], f))]\n",
    "        for each_title_json in extracted_title_json:\n",
    "\n",
    "            topics_list = []\n",
    "            try:\n",
    "                with open(extracted_title_folders[each] + '/' + each_title_json, 'rb') as f:\n",
    "                    read_title = json.load(f)\n",
    "\n",
    "                topics_list.append(read_title['Title'].replace('\\x0c',''))\n",
    "                topics_list.append(read_title['Date'])\n",
    "                topics_list.append(extracted_title_folders[each].split('/')[-1])\n",
    "                topics_list.append(each_title_json[6:-5])\n",
    "            except UnicodeDecodeError:\n",
    "                print(\"Wrong file type!\")\n",
    "            except:\n",
    "                print(\"Cannot read %s file!\" %each_title_json)\n",
    "\n",
    "\n",
    "            each_info_json = 'keyInfo' + each_title_json[5:]\n",
    "            each_extracted_info_folders = extracted_title_folders[each].replace(Topics_File_Folder, Variables_File_Folder)\n",
    "            try:\n",
    "                with open(each_extracted_info_folders + '/' + each_info_json, 'rb') as f:\n",
    "                    read_info = json.load(f)\n",
    "\n",
    "                topics_list.append(read_info[list(read_info.keys())[0]])\n",
    "                for key in range(1, len(read_info.keys())):\n",
    "                    variables_list = []\n",
    "                    variables_list.append(list(read_info.keys())[key])\n",
    "                    variables_list.append(read_info[list(read_info.keys())[key]])\n",
    "                    variables_list.append(read_title['Title'].replace('\\x0c',''))\n",
    "                    variables_list.append(each_info_json[8:-5])\n",
    "                    \n",
    "                    variables_table.append(variables_list)\n",
    "\n",
    "            except UnicodeDecodeError:\n",
    "                print(\"Wrong file type!\")\n",
    "\n",
    "            except:\n",
    "                print(\"Cannot read %s file!\" %each_info_json)\n",
    "                count_failed_info_file = count_failed_info_file + 1\n",
    "\n",
    "\n",
    "            variables_table.append(variables_list)\n",
    "            topics_table.append(topics_list)\n",
    "    \n",
    "    return topics_table, variables_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    Topics_File_Folder = \"/ExtractVariableTitle_1/\"\n",
    "    Variables_File_Folder = \"/ExtractFiles/\"\n",
    "    topics_table, variables_table = read_title_info(Topics_File_Folder, Variables_File_Folder)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_df = pd.DataFrame.from_dict(variables_table)\n",
    "# variables_df\n",
    "variables_df.columns = ['Variable_lable', 'Variable_def', 'Variable_topic', 'File_id']\n",
    "variables_df.to_csv(\"CBSMicrodataVariables_NL.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Category</th>\n",
       "      <th>File_id</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Productiestatistieken 2017</td>\n",
       "      <td>april-2019-19</td>\n",
       "      <td>industrie-en-energie</td>\n",
       "      <td>ps_waterafval</td>\n",
       "      <td>Dit documentatierapport beschrijft de main, de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Productiestatistieken 2017</td>\n",
       "      <td>april-2019-19</td>\n",
       "      <td>industrie-en-energie</td>\n",
       "      <td>ps_industrie</td>\n",
       "      <td>Dit documentatierapport beschrijft de main, de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prodcom; verkopen; industriële producten naar ...</td>\n",
       "      <td>maart-2018-3</td>\n",
       "      <td>industrie-en-energie</td>\n",
       "      <td>prodcom</td>\n",
       "      <td>De bestanden zijn beschikbaar over de perioden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Conjunctuurtest industrie</td>\n",
       "      <td>9-maart-2011</td>\n",
       "      <td>industrie-en-energie</td>\n",
       "      <td>conjunctuurtest-industrie-micordata</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Productiestatistieken 2017</td>\n",
       "      <td>april-2019-19</td>\n",
       "      <td>industrie-en-energie</td>\n",
       "      <td>ps_delfstoffenwinning</td>\n",
       "      <td>Dit documentatierapport beschrijft de main, de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title           Date  \\\n",
       "0                        Productiestatistieken 2017   april-2019-19   \n",
       "1                        Productiestatistieken 2017   april-2019-19   \n",
       "2  Prodcom; verkopen; industriële producten naar ...   maart-2018-3   \n",
       "3                         Conjunctuurtest industrie    9-maart-2011   \n",
       "4                        Productiestatistieken 2017   april-2019-19   \n",
       "\n",
       "               Category                              File_id  \\\n",
       "0  industrie-en-energie                        ps_waterafval   \n",
       "1  industrie-en-energie                         ps_industrie   \n",
       "2  industrie-en-energie                              prodcom   \n",
       "3  industrie-en-energie  conjunctuurtest-industrie-micordata   \n",
       "4  industrie-en-energie                ps_delfstoffenwinning   \n",
       "\n",
       "                                               Notes  \n",
       "0  Dit documentatierapport beschrijft de main, de...  \n",
       "1  Dit documentatierapport beschrijft de main, de...  \n",
       "2  De bestanden zijn beschikbaar over de perioden...  \n",
       "3                                               None  \n",
       "4  Dit documentatierapport beschrijft de main, de...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_df = pd.DataFrame.from_dict(topics_table)\n",
    "topics_df.columns = ['Title', 'Date', 'Category', 'File_id', 'Notes']\n",
    "topics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** None\n",
      "**** None\n",
      "**** None\n",
      "**** None\n",
      "**** None\n",
      "**** None\n",
      "**** None\n",
      "**** None\n",
      "**** None\n",
      "**** None\n",
      "**** None\n"
     ]
    }
   ],
   "source": [
    "### Normalize Date format ###\n",
    "new_date = []\n",
    "for each in topics_df['Date']:\n",
    "    try:\n",
    "        splited_date = each.split('-')\n",
    "    \n",
    "        if splited_date[0].isdigit() :\n",
    "            if int(splited_date[0]) < 100: \n",
    "                if splited_date[2].isdigit() and int(splited_date[2]) > 1000:\n",
    "                    new_each = each\n",
    "                    new_date.append(each)\n",
    "                else:\n",
    "                    if splited_date[2][0:4].isdigit():\n",
    "                        new_each = splited_date[0] + '-' + splited_date[1] + '-' + splited_date[2][0:4]\n",
    "                        new_date.append(each)\n",
    "                    else:\n",
    "                        new_each = splited_date[0] + '-' + splited_date[1][:-4] + '-' + splited_date[1][-4:]\n",
    "                        new_date.append(each)\n",
    "            else:\n",
    "                new_each = splited_date[1] + '-' + splited_date[2] + '-' + splited_date[0]\n",
    "                new_date.append(each)\n",
    "                    \n",
    "\n",
    "        else:\n",
    "            if splited_date[1].isdigit():\n",
    "                if splited_date[2].isdigit():\n",
    "                    new_each = splited_date[2] + '-' + splited_date[0] + '-' + splited_date[1]\n",
    "                    new_date.append(new_each)\n",
    "                else:\n",
    "                    new_each = '00' + '-' + splited_date[0] + '-' + splited_date[1]\n",
    "                    new_date.append(new_each)\n",
    "            else:\n",
    "                if splited_date[1][0:4].isdigit():\n",
    "                    new_each = '00' + '-' + splited_date[0] + '-' + splited_date[1][0:4]\n",
    "                    new_date.append(new_each)\n",
    "                else:\n",
    "                    if splited_date[2].isdigit():\n",
    "                        new_each = each[1:0]\n",
    "                        new_date.append(new_each)\n",
    "                    else:\n",
    "                        new_date.append(None)\n",
    "\n",
    "    except:\n",
    "        new_date.append(None)\n",
    "        print(\"****\",each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topics_df['Date'] = new_date\n",
    "topics_df.to_csv(\"CBSMicrodataInfoNL_2.csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_df = pd.DataFrame.from_dict(variables_table)\n",
    "variables_df.to_csv(\"CBSMicrodataVariablesNL.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Translated by Google Sheet###\n",
    "# Read translated file #\n",
    "# topics_df_EN = pd.read_csv('CBSMicrodataInfoNL_GoogleTrans.tsv', sep='\\t')[['Title', 'Date', 'Category', 'Notes', 'Title_EN', 'Date_EN', 'Category_EN', 'Notes_EN']]\n",
    "# variables_df_EN = pd.read_csv('CBSMicrodataVariablesNL_GoogleTrans.tsv', sep='\\t')[['Variable_lable', 'Variable_def', 'Variable_topic', 'Variable_def_EN', 'Variable_topic_EN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# topics_df_EN = topics_df_EN.replace(np.NaN, '')\n",
    "# topics_df_EN = topics_df_EN.replace('!', '')\n",
    "# topics_df_EN = topics_df_EN.replace('#VALUE!', '')\n",
    "# topics_df_EN\n",
    "\n",
    "# variables_df_EN = variables_df_EN.replace(np.NaN, '')\n",
    "# variables_df_EN = variables_df_EN.replace('#VALUE!', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topics_df_EN.to_csv(\"CBSMicrodataInfoEN.csv\", index=None)\n",
    "# variables_df_EN.to_csv(\"CBSMicrodataVariablesEN.csv\", index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
